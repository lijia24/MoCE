#bash scripts/run_train.sh configs/ucf101/ucf_train.yaml
#bash scripts/run_train_debug_2.sh configs/ucf101/ucf_train.yaml
resume:
pretrain:
seed: 1024
data:
    dataset: ucf101
    modality: video
    num_segments: 8
    seg_length: 1       # no use
    batch_size: 256
    workers: 8
    num_classes: 101
    image_tmpl: 'img_{:05d}.jpg' # no used
    train_root: 'xxx/ucf101'
    train_list: 'lists/ucf101/train_all.txt' 
    val_root: 'xxx/ucf101'
    val_list: 'lists/ucf101/val.txt'
    label_list: 'lists/ucf101/ucf101_label_merged.csv'
    spatial_label_list: 'lists/ucf101/ucf101_spatial_label.csv'
    template_label_list: 'lists/ucf101/ucf101_temporal_label.csv'
    input_size: 224
    random_shift: True
    output_path: exps_MoTE
network:
    arch: ViT-B/16      #ViT-B/32 ViT-B/16
    init: True
    tm: False           # no use
    drop_out: 0.0 
    emb_dropout: 0.0
    sim_header: Transf  # [Transf, None] 'Transf'ï¼š6-layer temporal transformer  'None': mean temporal pooling
    interaction: DP     # [DP] 'DP': mean temporal pooling
    joint_st: False     # whether use joint space-time attention in the transformer (default: False)
    drop: 0      
    fix_text: True
    fix_video: False
    num_experts: 4      #  >1: MoTE; <=1: mlp
solver:
    type: cosine
    epochs: 30
    start_epoch: 0
    epoch_offset: 0
    optim: adamw
    lr: 5.e-5
    lr_warmup_step: 5
    weight_decay: 0.2
    loss_type: CE
    evaluate: False     # only run evaluation
    clip_ratio: 0.07
    grad_accumulation_steps: 1
logging:
    print_freq: 10
    eval_freq: 1